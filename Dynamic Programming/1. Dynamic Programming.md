# Dynamic Programming

**Dynamic Programming** is both a mathematical optimization method and a computer programming method. The method was developed by Richard Bellman in the 1950s and has found applications in numerous fields, from aerospace engineering to economics.

In both contexts it refers to simplifying a complicated problem by breaking it down into _simpler sub-problems_ in a recursive manner. While some decision problems cannot be taken apart this way, decisions that span several points in time do often break apart recursively. Likewise, in computer science, if a problem can be solved optimally by breaking it into sub-problems and then recursively finding the optimal solutions to the sub-problems, then it is said to have _optimal substructure_.

There are two key attributes that a problem must have in order for dynamic programming to be applicable: **_Optimal Substructure_** and **_Overlapping Subproblems_**. If a problem can be solved by combining optimal solutions to non-overlapping sub-problems, the strategy is called "Divide and Conquer" instead. This is why merge sort and quick sort are not classified as dynamic programming problems.

## Overlapping Subproblems

Overlapping sub-problems means that the space of sub-problems must be small, that is, any recursive algorithm solving the problem should solve the same sub-problems over and over, rather than generating new sub-problems. A problem is said to have overlapping subproblems if the problem can be broken down into subproblems which are reused several times or a recursive algorithm for the problem solves the same subproblem over and over rather than always generating new subproblems.

## Optimal Substructure

Optimal substructure means that the solution to a given optimization problem can be obtained by the combination of optimal solutions to its sub-problems. Such optimal substructures are usually described by means of recursion. A problem is said to have optimal substructure if an optimal solution can be constructed from optimal solutions of its subproblems. This property is used to determine the usefulness of dynamic programming and greedy algorithms for a problem.

## An Example - Fibonacci

Consider the recursive formulation for generating the Fibonacci series: `fib(i)` = `fib(i-1)` + `fib(i-2)`, with base case `fib(1)` = `fib(2)` = `1`.

```js
function fib(num) {
  if (num <= 2) return 1;
  return fib(num - 1) + fib(num - 2);
}
```

Then `fib(43)` = `fib(42)` + `fib(41)`, and `fib(42)` = `fib(41)` + `fib(40)`. Now `fib(41)` is being solved in the recursive sub-trees of both `fib(43)` as well as `fib(42)`. Even though the total number of sub-problems is actually small (only 43 of them), we end up solving the same problems over and over if we adopt a naive recursive solution such as this.

![Illustration of how the recursive calls for the recursive Fibonacci solution grows over larger inputs](https://i.stack.imgur.com/kgXDS.png)

Dynamic programming takes account of this fact and solves each sub-problem only once. This can be achieved in either of two ways:

- **_Top-down approach:_** This is the direct fall-out of the recursive formulation of any problem. If the solution to any problem can be formulated recursively using the solution to its sub-problems, and if its sub-problems are overlapping, then one can easily memoize or store the solutions to the sub-problems in a table. Whenever we attempt to solve a new sub-problem, we first check the table to see if it is already solved. If a solution has been recorded, we can use it directly, otherwise we solve the sub-problem and add its solution to the table.
- **_Bottom-up approach:_** Once we formulate the solution to a problem recursively as in terms of its sub-problems, we can try reformulating the problem in a bottom-up fashion: try solving the sub-problems first and use their solutions to build-on and arrive at solutions to bigger sub-problems. This is also usually done in a tabular form by iteratively generating solutions to bigger and bigger sub-problems by using the solutions to small sub-problems. For example, if we already know the values of `fib(41)` and `fib(40)`, we can directly calculate the value of `fib(42)`.

## Memoization (Top-Down Approach)

```js
function memoizedFibHOF() {
  //  Create a cache variable to store previous results
  const cache = {};

  return function fib(num) {
    //  If the number we're looking for is already in the cache:
    if (num in cache) {
      //  Simply return the cached result
      return cache[num];
    }

    //  Otherwise, just calculate the result like usual
    if (num <= 2) {
      return num;
    }

    //  Don't forget to store new results in the cache!
    cache[num] = fib(num - 1) + fib(num - 2);
    return cache[num];
  };
}

const memoizedFib = memoizedFibHOF();
```

## Tabulation (Bottom-Up Approach)

```js
function tabulatedFibHOF() {
  //  Create a cache variable to store previous results
  const cache = [0, 1, 1];

  return function fib(num) {
    //  If the number we're looking for is already in the cache:
    if (num in cache) {
      //  Simply return the cached result
      return cache[num];
    }

    //  Otherwise, calculate next values
    //  based on previously cached results
    for (let i = cache.length; i < num; i++) {
      cache.push(cache[i - 1] + cache[i - 2]);
    }

    return cache[cache.length - 1];
  };
}

const tabulatedFib = tabulatedFibHOF();
```

---

## References

[Wikipedia - Dynamic programming](https://en.wikipedia.org/wiki/Dynamic_programming)

[Wikipedia - Overlapping subproblems](https://en.wikipedia.org/wiki/Overlapping_subproblems)

[Wikipedia - Optimal substructure](https://en.wikipedia.org/wiki/Optimal_substructure)
